import os, sys, re
import numpy as np
import pandas as pd

import subprocess
from multiprocessing import Pool

# %load_ext autoreload
# %autoreload 2

"""
- (1) SSFNíŒŒì¼ì— disjointí•˜ê²Œ GPU_IDí• ë‹¹.
- (2) mpë¡œ run

ì•„ì§ classë¡œ wrappingí•´ì•¼í• ë§Œí•œ ìˆ˜ì¤€ì„ ì•„ë‹ˆë¼ì„œ ê·¸ëƒ¥ í•¨ìˆ˜ë“¤ë¡œ ì¤€ë¹„í•¨.
"""



def alloc_GPU(_df_SSFN):

    l_GPU_ToUse = [0, 3, 5, 7]
    
    d_GPU_ToMap = {
        0: 2, # 2ë¡œ ì¡ì•„ì•¼ 0ì´ ë‚˜ì˜´.
        3: 1, # 1ë¡œ ì¡ì•„ì•¼ 3ì´ ë‚˜ì˜´.
    }    

    print(_df_SSFN)

    arr_split = np.array_split(_df_SSFN.index.tolist(), len(l_GPU_ToUse))

    sr_GPU_ID = pd.Series(
        [_gpu_id for (_arr, _gpu_id) in zip(arr_split, l_GPU_ToUse) for _ in range(len(_arr))],
        name='gpu_id',
        index=_df_SSFN.index
    )
    sr_GPU_ID = sr_GPU_ID.map(lambda x: d_GPU_ToMap[x] if x in d_GPU_ToMap else x)
    # display(sr_GPU_ID)
    print(sr_GPU_ID.value_counts())


    df_RETURN = pd.concat([_df_SSFN, sr_GPU_ID], axis=1)

    return df_RETURN



### a single run of batch
## ì´ í•¨ìˆ˜ëŠ” ìƒí™©ì— ë”°ë¼ ë§Œë“¤ ì—¬ì§€ê°€ ë†’ìŒ. (ë³µë¶™í•´ì„œ ê°€ì ¸ë‹¤ ì“°ëŠ” ìš©ë„.)
def run_SUM2HLA(_args):

    _index, _Sim_No, _ncp_1st, _fpath_IN, _fpath_OUT, _gpu_id = _args

    print(f"=====[ index: {_index} / NCP_1st: {_ncp_1st} / Sim_No: {_Sim_No} ]")

    cmd = [
        "conda", "run", "-n", "jax_gpu", # 'jax_gpu' í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ë„ë¡ ì§€ì •
        "python",
        "SUM2HLA.py",
        "--sumstats", _fpath_IN,
        "--ref", "/data02/wschoi/_ClusterPhes_v4/LD_from_HLA_reference_panel/REF_T1DGC.hg19.SNP+HLA",
        "--out", _fpath_OUT,
        "--gpu-id", str(_gpu_id)
    ]

    # print(cmd)

    result = subprocess.run(cmd, capture_output=True, text=True, env=os.environ.copy())
    
    if result.returncode != 0:
        # ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš°, ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì¶œë ¥
        return False
    return True



def print_PID():

    print(os.getpid())

    return 0


def do_multiprocessing(_df_SSFN, _chunksize, _func, _l_GPU_ToUse = [0, 3, 5, 7]):

    """
    - ipynbì—ì„œ ì“¸ ê²½ìš°, ì–˜ëŠ” ë°˜ë“œì‹œ "if __name == `__main__`:" ì˜ guard lineë‚´ì—ì„œ ì¨ì•¼ í•¨.
    
    """
    print(f"âœ… ì´ ì»¤ë„ì˜ PIDëŠ” {os.getpid()} ì…ë‹ˆë‹¤. ì´ ë²ˆí˜¸ë¥¼ ê¸°ë¡í•´ë‘ì„¸ìš”.")    
    
    tasks = _df_SSFN.itertuples(name=None)
    
    pool = Pool(processes=len(_l_GPU_ToUse))

    try:
        # pool.mapì„ ì‹¤í–‰. ì´ í•¨ìˆ˜ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ì—¬ê¸°ì„œ ëŒ€ê¸°í•©ë‹ˆë‹¤.
        results = pool.map(_func, tasks, chunksize=_chunksize)
        print("\n--- ëª¨ë“  ì‘ì—… ì •ìƒ ì™„ë£Œ ---")

        sr_SUCCESS = pd.Series(list(results), name="success")
        print(sr_SUCCESS)
        print(sr_SUCCESS.all())

    except KeyboardInterrupt:
        # Ctrl+C ë˜ëŠ” Jupyterì˜ ì¤‘ë‹¨ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì´ ë¸”ë¡ì´ ì‹¤í–‰ë©ë‹ˆë‹¤.
        print("\nğŸš¨ ì‚¬ìš©ìì— ì˜í•´ ì‘ì—…ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë“  ìì‹ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤...")
        
        # pool.terminate() : í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì‘ì—…ë“¤ì„ ì¦‰ì‹œ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤. (ê°€ì¥ ì¤‘ìš”!)
        pool.terminate()
        
        # pool.join() : ìì‹ í”„ë¡œì„¸ìŠ¤ë“¤ì´ ì™„ì „íˆ ì¢…ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        pool.join()
        
        print("âœ… ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    finally:
        # ì •ìƒ ì¢…ë£Œ ë˜ê±°ë‚˜, ì˜ˆì™¸(ì¤‘ë‹¨)ê°€ ë°œìƒí•´ë„ í•­ìƒ ì‹¤í–‰ë©ë‹ˆë‹¤.
        # ì—´ë ¤ìˆëŠ” í’€ì„ ë‹«ì•„ì¤ë‹ˆë‹¤.
        pool.close()
        pool.join()


    return sr_SUCCESS